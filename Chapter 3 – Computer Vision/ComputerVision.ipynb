{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhLevdcZvGRy99r61H1geG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shadoww002/PyTorch-Learning/blob/main/Chapter%203%20%E2%80%93%20Computer%20Vision/ComputerVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2CLaFmM0Zwc"
      },
      "outputs": [],
      "source": [
        "## IMPORT LIBRARIES\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting Started With FashinMINST Datasets\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"Data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"Data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "A6ShOELd79mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data) , len(test_data)"
      ],
      "metadata": {
        "id": "_4YUY7VIgG0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data[0].shape"
      ],
      "metadata": {
        "id": "eFHyE6sOeHt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Lets see The data\n",
        "\n",
        "train_data[0] , train_data.test_labels[0]"
      ],
      "metadata": {
        "id": "drCND6hMhDf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "CM3yWJYDhQx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "HRp-GWrLhYaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image , lable = train_data[0]\n",
        "image.size()"
      ],
      "metadata": {
        "id": "rv2hIHDnhh7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = train_data.classes\n",
        "class_name"
      ],
      "metadata": {
        "id": "GrgEFBNQvVpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualise The Data\n",
        "plt.title(class_name[lable])\n",
        "plt.imshow(image.squeeze())"
      ],
      "metadata": {
        "id": "9ylWMt2khlru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(class_name[lable])\n",
        "plt.imshow(image.squeeze() ,\n",
        "           cmap = \"gray\")"
      ],
      "metadata": {
        "id": "jfAT2rI-uPxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ploting The Random Images\n",
        "torch.manual_seed(42)\n",
        "plt.figure(figsize=(8,8))\n",
        "rows , cols = 4 , 4\n",
        "\n",
        "for i in range(1 , rows*cols+1):\n",
        "  idx = torch.randint(0,len(train_data),size=[1])\n",
        "  image , label = train_data[idx.squeeze()]\n",
        "  class_name = train_data.classes[label]\n",
        "  plt.subplot(rows , cols , i)\n",
        "  plt.title(class_name)\n",
        "  plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "  plt.axis(False)\n"
      ],
      "metadata": {
        "id": "GtnxylXXv56U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.utils"
      ],
      "metadata": {
        "id": "9HHUyZfC9bcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Preparing DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                             batch_size = 32,\n",
        "                             shuffle = True)\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size = 32,\n",
        "                             shuffle = False)"
      ],
      "metadata": {
        "id": "kW-BMddwyCB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader) , len(test_dataloader)"
      ],
      "metadata": {
        "id": "ImbgDP10ziCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "60000/32 , 10000/32"
      ],
      "metadata": {
        "id": "wRr0VqBO-UF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Interact with the Data Loader\n",
        "train_features_batch , train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape , train_labels_batch.shape"
      ],
      "metadata": {
        "id": "nI0jFERr-o8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = train_data.classes"
      ],
      "metadata": {
        "id": "qotnVCLOBNsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Show a Sample\n",
        "random_idx = torch.randint(0 , len(train_features_batch) , size=[1]).item()\n",
        "img , label = train_features_batch[random_idx] , train_labels_batch[random_idx]\n",
        "plt.title(class_name[label])\n",
        "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "wUl3fqVr_TUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Understnding the Flatten Layer Concept\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "x = train_features_batch[0]\n",
        "\n",
        "output = flatten_model(x)\n",
        "\n",
        "x.shape , output.shape"
      ],
      "metadata": {
        "id": "EEzvLhxqBEKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a BaselIne Model\n",
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,input_shape ,hidden_units, output_shape):\n",
        "    super().__init__()\n",
        "    self.LayerStack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self , x):\n",
        "    return self.LayerStack(x)"
      ],
      "metadata": {
        "id": "O1TJJn5o1iFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "28*28"
      ],
      "metadata": {
        "id": "-bQpOV__gWfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape=28*28,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_name)\n",
        ").to(\"cpu\")\n",
        "\n",
        "model_0"
      ],
      "metadata": {
        "id": "ro-TRAUw2Bwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Import HELPER Functions\n",
        "\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "ggxTi4uP3sC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "igHGqYbx4Ant"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a Function To Time Experiments\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def print_train_time (\n",
        "    start : float ,\n",
        "    end : float,\n",
        "    device : torch.device = None):\n",
        "\n",
        "  total_time = end - start\n",
        "  print(f\"Train Time : {total_time:.3f} Sec on {device}\")\n",
        "\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "14cnwwXP4Me0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader.dataset)"
      ],
      "metadata": {
        "id": "vvszI92NZBAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Building a Train and Test loop\n",
        "\n",
        "# import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "#setting seed and start time\n",
        "torch.manual_seed(42)\n",
        "train_start_time_cpu = timer()\n",
        "\n",
        "# Set epochs\n",
        "epochs = 3\n",
        "\n",
        "##creating a loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch : {epoch}\\n------\")\n",
        "  ##Train Loop\n",
        "  train_loss = 0\n",
        "  for batch , (X,y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    loss = loss_fn(y_pred , y)\n",
        "    train_loss += loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 400 == 0 :\n",
        "      print(f\"Looked At : {batch*len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  train_loss = train_loss/len(train_dataloader)\n",
        "\n",
        "  ##Testing LOOP\n",
        "\n",
        "  test_loss , test_acc = 0 ,0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X , y in test_dataloader:\n",
        "\n",
        "      test_pred = model_0(X)\n",
        "\n",
        "      test_loss = test_loss + loss_fn(test_pred , y)\n",
        "\n",
        "      test_acc += accuracy_fn(y_true=y , y_pred= test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  print(f\"\\nTrain Loss : {train_loss:.5f} | test Loss : {test_loss:.5f} | Test Acc : {test_acc:.2f}%\\n\")\n",
        "\n",
        "train_end_time_cpu = timer()\n",
        "total_train_time_cpu = print_train_time(start=train_start_time_cpu,\n",
        "                                        end=train_end_time_cpu,\n",
        "                                        device = str(next(model_0.parameters()).device))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nX-TRsWm7BlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Making Predictions From BaseLine Model i.e Model_0"
      ],
      "metadata": {
        "id": "C4Ivu4bcVHP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model : torch.nn.Module,\n",
        "              data_loader : torch.utils.data.DataLoader,\n",
        "              loss_fn : torch.nn.Module,\n",
        "              accuracy_fn):\n",
        "\n",
        "  loss , acc = 0 , 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X , y in data_loader:\n",
        "\n",
        "      y_pred = model(X)\n",
        "\n",
        "      loss += loss_fn(y_pred,y)\n",
        "      acc += accuracy_fn(y_pred=y_pred.argmax(dim=1) ,\n",
        "                         y_true = y )\n",
        "\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"Model_Name\" : model.__class__.__name__,\n",
        "          \"Model_Loss\" : loss.item(),\n",
        "          \"Model_acc\" : acc}"
      ],
      "metadata": {
        "id": "91FouIIj4Zl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results = eval_model(model=model_0,\n",
        "                            data_loader=test_dataloader,\n",
        "                            loss_fn = loss_fn,\n",
        "                            accuracy_fn=accuracy_fn)\n",
        "\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "HEOVKmfk6LFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Lets Set Device Agnoistic Code and Make Use of GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "-I7RRkqh7A4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Making The Model With NON-Linearlity\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self,input_shape ,hidden_units , output_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.Non_linearStack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self , x ):\n",
        "    return self.Non_linearStack(x)"
      ],
      "metadata": {
        "id": "NYGVcSrc7RBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = FashionMNISTModelV1(\n",
        "    input_shape=28*28,\n",
        "    hidden_units=16,\n",
        "    output_shape=len(class_name)\n",
        ").to(device)\n",
        "\n",
        "model_1 , next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "FuuGfui6Eemb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Setting Loss And Optmizer Function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr = 0.1)"
      ],
      "metadata": {
        "id": "AKHxsMZ_CQEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Lets Functionise the Train And Test LOOP"
      ],
      "metadata": {
        "id": "myPlGBOwC8jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating Train Loop Function\n",
        "def Train_Step(model : torch.nn.Module,\n",
        "               train_dataloader : torch.utils.data.DataLoader,\n",
        "               loss_fn : torch.nn.Module,\n",
        "               optimizer : torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device : torch.device = device):\n",
        "\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  model.train()\n",
        "  model.to(device)\n",
        "\n",
        "  for batch , (X , y) in enumerate(train_dataloader):\n",
        "\n",
        "    X, y = X.to(device) , y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred , y)\n",
        "    train_loss += loss\n",
        "\n",
        "    acc = accuracy_fn(y_pred=y_pred.argmax(dim=1),\n",
        "                        y_true = y)\n",
        "    train_acc += acc\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  print(f\"Train_loss : {loss:.5f} | Train_Acc : {acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "pjoEc8sfCYnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating Function for testing LOOP\n",
        "def Test_Step(model : torch.nn.Module,\n",
        "               test_dataloader : torch.utils.data.DataLoader,\n",
        "               loss_fn : torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device : torch.device = device):\n",
        "\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  model.eval()\n",
        "  model.to(device)\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X , y in test_dataloader :\n",
        "\n",
        "      X,y = X.to(device) , y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "\n",
        "      test_loss = loss_fn(test_pred , y)\n",
        "      loss += test_loss\n",
        "\n",
        "      test_acc = accuracy_fn(y_pred=test_pred.argmax(dim=1),\n",
        "                             y_true = y)\n",
        "      acc += test_acc\n",
        "\n",
        "  loss = loss/len(test_dataloader)\n",
        "  acc = acc/len(test_dataloader)\n",
        "\n",
        "  print(f\"Test_loss : {loss:.5f} | Test_Acc : {acc:.2f}%\\n\")\n"
      ],
      "metadata": {
        "id": "YQljhAYrLAcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train and Test the Model"
      ],
      "metadata": {
        "id": "IBzzIIETQJsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "#setting seed and start time\n",
        "torch.manual_seed(42)\n",
        "train_start_time_gpu = timer()\n",
        "# Set epochs\n",
        "epochs = 3\n",
        "\n",
        "##creating a loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch : {epoch}\\n------\")\n",
        "  ##Train Loop\n",
        "  Train_Step(model = model_1 ,\n",
        "             train_dataloader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device\n",
        "             )\n",
        "\n",
        "\n",
        "  ##Testing LOOP\n",
        "  Test_Step(model=model_1,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device = device\n",
        "             )\n",
        "\n",
        "train_end_time_gpu = timer()\n",
        "total_train_time_gpu = print_train_time(start=train_start_time_gpu,\n",
        "                                        end=train_end_time_gpu,\n",
        "                                        device = device)\n"
      ],
      "metadata": {
        "id": "l4wbH0buLhQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "DHRESMz0Q_AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model : torch.nn.Module,\n",
        "              data_loader : torch.utils.data.DataLoader,\n",
        "              loss_fn : torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "               device : torch.device = device):\n",
        "\n",
        "  loss , acc = 0 , 0\n",
        "  model.eval()\n",
        "  model.to(device)\n",
        "  with torch.inference_mode():\n",
        "    for X , y in data_loader:\n",
        "      X , y = X.to(device) , y.to(device)\n",
        "\n",
        "      y_pred = model(X)\n",
        "\n",
        "      loss += loss_fn(y_pred,y)\n",
        "      acc += accuracy_fn(y_pred=y_pred.argmax(dim=1) ,\n",
        "                         y_true = y )\n",
        "\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"Model_Name\" : model.__class__.__name__,\n",
        "          \"Model_Loss\" : loss.item(),\n",
        "          \"Model_acc\" : acc}"
      ],
      "metadata": {
        "id": "CHvUYcJuYLHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = eval_model(model=model_1,\n",
        "                             data_loader=test_dataloader,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             loss_fn=loss_fn,\n",
        "                             device=device)"
      ],
      "metadata": {
        "id": "iIUMv3DGXbJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "id": "mkZYTRG1Y0cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning And Building CNN Model**"
      ],
      "metadata": {
        "id": "II9O-WlpPegT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a CNN\n",
        "class FashionMNiSTModelV2(nn.Module):\n",
        "  def __init__(self , input_shape , hidden_units , output_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  padding=1,\n",
        "                  stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=1)\n",
        "    )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units,hidden_units,3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units , hidden_units , 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*13*13,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self , x):\n",
        "    x = self.block_1(x)\n",
        "    # print(x.shape)\n",
        "    x = self.block_2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    # print(x.shape)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "KycVXV1UY3pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNiSTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_name)).to(device)\n",
        "\n",
        "model_2"
      ],
      "metadata": {
        "id": "HvNvUQO7UqB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Understanding The Conv2D and MaxPool2d Layers"
      ],
      "metadata": {
        "id": "366rCpCTbNtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create sample batch of random numbers with same size as image batch\n",
        "images = torch.randn(size=(32, 3, 64, 64)) # [batch_size, color_channels, height, width]\n",
        "test_image = images[0] # get a single image for testing\n",
        "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Single image pixel values:\\n{test_image}\")"
      ],
      "metadata": {
        "id": "OdHGKoBGbxG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a convolutional layer with same dimensions as TinyVGG\n",
        "# (try changing any of the parameters and see what happens)\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=10,\n",
        "                       kernel_size=3,\n",
        "                       stride=1,\n",
        "                       padding=0) # also try using \"valid\" or \"same\" here\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_layer(test_image) # Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input)"
      ],
      "metadata": {
        "id": "vzAl9B6lbyx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add extra dimension to test image\n",
        "test_image.unsqueeze(dim=0).shape"
      ],
      "metadata": {
        "id": "FdgMql4rb6eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass test image with extra dimension through conv_layer\n",
        "conv_layer(test_image.unsqueeze(dim=0)).shape"
      ],
      "metadata": {
        "id": "uoHXmYRucDgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out original image shape without and with unsqueezed dimension\n",
        "print(f\"Test image original shape: {test_image.shape}\")\n",
        "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")\n",
        "\n",
        "# Create a sample nn.MaxPoo2d() layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# Pass data through just the conv_layer\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "# Pass data through the max pool layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")"
      ],
      "metadata": {
        "id": "zQ1ST-6FcFBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a random tensor with a similar number of dimensions to our images\n",
        "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
        "print(f\"Random tensor:\\n{random_tensor}\")\n",
        "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
        "\n",
        "# Create a max pool layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2) # see what happens when you change the kernel_size value\n",
        "\n",
        "# Pass the random tensor through the max pool layer\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor:\\n{max_pool_tensor} <- this is the maximum value from random_tensor\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
      ],
      "metadata": {
        "id": "xc5x1ISbchwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## step up tha Optimizer and Loss Function\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr = 0.1)"
      ],
      "metadata": {
        "id": "55w6YdVCCVHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training and Testing LOOP\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "#measure Time\n",
        "from timeit import default_timer as timer\n",
        "train_start_time_model_2 = timer()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch : {epoch}\\n ---\")\n",
        "\n",
        "  Train_Step(model= model_2,\n",
        "             train_dataloader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device = device)\n",
        "\n",
        "  Test_Step(model=model_2,\n",
        "            test_dataloader=test_dataloader,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            loss_fn=loss_fn,\n",
        "            device = device)\n",
        "\n",
        "\n",
        "train_end_time_model_2 = timer()\n",
        "total_train_time_model_2 = print_train_time(start=train_start_time_model_2,\n",
        "                                            end=train_end_time_model_2,\n",
        "                                            device = device\n",
        "                                            )\n"
      ],
      "metadata": {
        "id": "ApksakXPC6i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## model_2 results\n",
        "model_2_results = eval_model(\n",
        "    model=model_2,\n",
        "    accuracy_fn=accuracy_fn,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    device = device\n",
        ")\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "c58vIfM8EuHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Lest Compare\n",
        "import pandas as pd\n",
        "\n",
        "compare_results = pd.DataFrame([model_0_results,model_1_results,model_2_results])\n",
        "compare_results"
      ],
      "metadata": {
        "id": "FVQtPAIaE8IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results[\"train_time\"] = [total_train_time_cpu ,total_train_time_gpu,total_train_time_model_2]\n",
        "compare_results"
      ],
      "metadata": {
        "id": "eQR7WyskHMxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Make and Evaluate Random Predictions with Best Model\n",
        "\n",
        "def make_predictions(model : nn.Module,\n",
        "                     data : list ,\n",
        "                     device : torch.device = device):\n",
        "  pred_probs =[]\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data :\n",
        "\n",
        "      sample = torch.unsqueeze(sample , dim = 0).to(device)\n",
        "\n",
        "      pred_logits = model(sample)\n",
        "\n",
        "      pred_prob = torch.softmax(pred_logits.squeeze() , dim = 0 )\n",
        "\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  return torch.stack(pred_probs)\n"
      ],
      "metadata": {
        "id": "PQU2JDFWoHuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# random.seed(42)\n",
        "\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "\n",
        "for sample , label in random.sample(list(test_data) , k = 9 ):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "test_samples[0].shape\n",
        "\n"
      ],
      "metadata": {
        "id": "vVeYoMjhprzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze() , cmap=\"gray\")\n",
        "plt.title(class_name[test_labels[0]])"
      ],
      "metadata": {
        "id": "NMj6rF1VrAbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make predictions\n",
        "pred_prods = make_predictions(model = model_2,\n",
        "                              data = test_samples)"
      ],
      "metadata": {
        "id": "ArMLG9Z9rlOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_prods[:4]"
      ],
      "metadata": {
        "id": "RRete3KKr3pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Probs to labels\n",
        "pred_classes = pred_prods.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "9Tz28M7zsKST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "eTUjAUtIsa5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot predictions\n",
        "plt.figure(figsize=(9,9))\n",
        "row = 3\n",
        "col = 3\n",
        "\n",
        "for i , sample in enumerate(test_samples):\n",
        "  plt.subplot(row,col,i+1)\n",
        "\n",
        "  plt.imshow(sample.squeeze(),cmap= \"gray\")\n",
        "\n",
        "  pred_label = class_name[pred_classes[i]]\n",
        "  truth_label = class_name[test_labels[i]]\n",
        "\n",
        "  title_text = f\"Pred : {pred_label} | Truth : {truth_label}\"\n",
        "\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text , c = \"g\" ,fontsize = 10 )\n",
        "  else: plt.title(title_text , c=\"r\" , fontsize = 10)\n",
        "\n",
        "  plt.axis(False)\n",
        "\n"
      ],
      "metadata": {
        "id": "4xW91-pzskUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Make predictions with trained model\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "    # Send data and targets to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # Do the forward pass\n",
        "    y_logit = model_2(X)\n",
        "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 32, so can perform on dim=1)\n",
        "    # Put predictions on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "# Concatenate list of predictions into a tensor\n",
        "y_pred_tensor = torch.cat(y_preds)"
      ],
      "metadata": {
        "id": "bVm4mwEHBj5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tensor.size()"
      ],
      "metadata": {
        "id": "DnBDgyV3DqNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mlxtend upgraded version\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher\n"
      ],
      "metadata": {
        "id": "ox-xdbqzAzt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "WglvaDf-EG9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_name)"
      ],
      "metadata": {
        "id": "FMOL_kWgGOAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = ConfusionMatrix(num_classes=len(class_name),task='multiclass')\n",
        "confmat_tensor = confmat(preds = y_pred_tensor,\n",
        "                         target = test_data.targets)\n",
        "\n",
        "fig , ax = plot_confusion_matrix(\n",
        "    conf_mat=confmat_tensor.numpy(),\n",
        "    class_names=class_name,\n",
        "    figsize=(8,5)\n",
        ")"
      ],
      "metadata": {
        "id": "t4YSm3FKDavG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nbstripout"
      ],
      "metadata": {
        "id": "TI-to3cexiuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAJYum0HxuvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}